---
title: "Sentiment analysis"
author: "Josephine (Aka the firebreather)"
date: "May 2, 2018"
output: html_document
---


#Welcome to the wonderful tale of the silver-scaled corrrelational dragon. We will follow the dragon as it embarks on an awesome new adventure! A sentiment analysis *insert scary music*
We don't need to set WD due to us using github


#Load in packages for our sentiment analysis.


```{r setup, include=FALSE}
library(tesseract) #This is for reading in the non-machinereadable PDFs - you need to download the danish part of it if using it yourself - code inserted below this chunk

#Run this line to get the danish stuff
danish <- tesseract("dan")
```

This is the code for getting the Danish part

**Run this** to get the danish stuff.
tesseract_download("dan")
danish <- tesseract("dan")



##Okay - the Dragon has come to a mountain.
##Aka, let us load in one article *Insert screaming smiley*
This mountain is an article from politiken. The dragon now tries to load in the article.


```{r}

#All this is commented out to save time - do you ever just run the entire code and regret it?
#A2 <- ocr("P_A1_fly_Y2011.pdf", engine = danish)

#Try with JP
#A1 <- ocr("J_A1_fly_Y2013.pdf", engine = danish)

#A3 <- ocr("b_A1_fly_Y2011.pdf", engine = danish)


#write.csv(A1, "A1JP.txt")

#write.csv(A2, "A1P.txt")

#write.csv(A3, "A1B.txt")
```


Try with machine readable stuff

```{r}
#Same reason for commenting out as above

#library(tm)
#library(pdftools)

#text = pdf_text("p_A1_fly_Y2011.pdf")

```



The dragon conquered the first mountain (actually it was just a small hill, called Himmelbjerget - but also a different hill - just for the fun of it).
Now it has come to a lot of hills that it needs to conquor in a systematic way, if it wants to live *Dam, dam, dam, daaaaam*

##The tale of the dragon and the systematic loop for reading PDF files

The fire breather has taken a decision. We will make two loops - one for machine-readable stuff using pdf_text and one for non-machine readable stuff using tesseract.

We will start out with the non-machinreadable due to a special fondness for tesserect (or because that is what will kill my computer and take hours, days, or...)

Below, we make a function for cleaning the text (Thanks Arnault for the inspiration for code).
```{r}

library(stringr)


cleanText <- function(string){
  # Make the text lowercase
  temp = tolower(string)
  
  #Now let us remove everything starting with a backslash _ Wuhuu, the code works now! :D
  temp = stringr::str_replace_all(temp, "[[:cntrl:]]", " ")
  
  #Okay, now let us remove everything that is in the bottom infomedia-don't-share-this-article-thingy
  temp = sub("alt materiale i infomedia.*", "", temp)
  
  #Okay, now it would be really cool if we could remove everything that starts with "https:" and ends with "infomedia" (everything in between this
  temp = sub("https.*infomedia", "", temp)
  
  #Okay, next step - let us remove everything before "id:" ( and the thing in the space after the id)
  #Best bet is to do like this (but might create issues if we have an article that include "id: " at some point, but we just can't do anything about this at the moment - assumption that this will be right
  temp = sub(".*id: ",  "", temp)
  
    
  #Okay, so now we just need to remove everything that is not letters or numbers.
  #And unfortunately we cannot use Arnaults function and need to make our own
  #I HATE DANISH!
  #But the below works
  temp = stringr::str_replace_all(temp, "\\W", " ") #\\W means all non-word characters - thus removes everything but letters and numbers
  
  #And now we need to remove every time we have double, triple or more spaces
  #Shrink down to just one white space
  temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
  
  #okay, so now we need to remove the ID number. We now that the ID number is the first thinghy in our string. So now we split the string by space (which we needed to do at some point anyway, and then remove the first element)
  temp = strsplit(temp, " ")[[1]]
  #And now we remove the first thing in the streng
  temp = temp[-1]

  return(temp)
}
```

And now we make a function for the sentiment analysis
```{r}
sentimentAnalysis <- function(string){
  
  temp = string
  
  
  return(temp)
}


```



And now for the loop

```{r}
library(rlist) #list.flatten


#Make a list of all the articles that are non-machinable (I have a folder - Because I'm cool!) (New word - yay! :D)

nmArticles = list.files(path = "C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/NonMachineRead")



#We can opeeeeeen the loooop! (Sing this in the same melody as "I can shoow you the woooorld!")



for (article in nmArticles){
  print (article) # just to be able to follow the code, see that it is working and stuff
  
  #Set temporary WD
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/NonMachineRead")
  
  #Okay, now we are ready to read in the article
  A <- ocr(article, engine = danish)
  
  #Okay, so our awesome function from the tesserect package helped us read the non machinable text.
  #However, we are now left with a character string. This is the same length as number of pages in the pdf - And we just want one long coherrent text
  #Is there an easier way to do this? Unlist did not work...
  AOut = NULL
  for (page in A){
    print(page)
    
    AOut = paste(AOut, page, article, sep ="")
  }
  
  #So, the loop above solved our problem - now we have the coherrent string
  #Cool. Now we want to clean the text
  cleanA = cleanText(AOut)
  
  #okay, so now we can move onto the next step... OUR SENTIMENT ANALYSIS! 
  #Let us just write a function... I need to learn to do functions instead, to avoid the insanely long loops from last semester
  
  
}



```





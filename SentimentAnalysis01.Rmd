---
title: "Sentiment analysis"
author: "Josephine (Aka the firebreather)"
date: "May 2, 2018"
output: html_document
---


#Welcome to the wonderful tale of the silver-scaled corrrelational dragon. We will follow the dragon as it embarks on an awesome new adventure! A sentiment analysis *insert scary music*
We don't need to set WD due to us using github


#Load in packages for our sentiment analysis.


```{r setup, include=FALSE}
library(tesseract) #This is for reading in the non-machinereadable PDFs - you need to download the danish part of it if using it yourself - code inserted below this chunk

#Run this line to get the danish stuff
danish <- tesseract("dan")
```

This is the code for getting the Danish part

**Run this** to get the danish stuff.
tesseract_download("dan")
danish <- tesseract("dan")



##Okay - the Dragon has come to a mountain.
##Aka, let us load in one article *Insert screaming smiley*
This mountain is an article from politiken. The dragon now tries to load in the article.


```{r}

#All this is commented out to save time - do you ever just run the entire code and regret it?
#A2 <- ocr("P_A1_fly_Y2011.pdf", engine = danish)

#Try with JP
#A1 <- ocr("J_A1_fly_Y2013.pdf", engine = danish)

#A3 <- ocr("b_A1_fly_Y2011.pdf", engine = danish)


#write.csv(A1, "A1JP.txt")

#write.csv(A2, "A1P.txt")

#write.csv(A3, "A1B.txt")
```


Try with machine readable stuff

```{r}
#Same reason for commenting out as above

#library(tm)
#library(pdftools)

#text = pdf_text("p_A1_fly_Y2011.pdf")

```



The dragon conquered the first mountain (actually it was just a small hill, called Himmelbjerget - but also a different hill - just for the fun of it).
Now it has come to a lot of hills that it needs to conquor in a systematic way, if it wants to live *Dam, dam, dam, daaaaam*

##The tale of the dragon and the systematic loop for reading PDF files

The fire breather has taken a decision. We will make two loops - one for machine-readable stuff using pdf_text and one for non-machine readable stuff using tesseract.

We will start out with the non-machinreadable due to a special fondness for tesserect (or because that is what will kill my computer and take hours, days, or...)

Below, we make a function for cleaning the text (Thanks Arnault for the inspiration for code).
```{r}

library(stringr)


cleanText <- function(string){
  #Set temporary WD
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/NonMachineRead")
  # Make the text lowercase
  temp = tolower(string)
  
  #Now let us remove everything starting with a backslash _ Wuhuu, the code works now! :D
  temp = stringr::str_replace_all(temp, "[[:cntrl:]]", " ")
  
  #Okay, now let us remove everything that is in the bottom infomedia-don't-share-this-article-thingy
  temp = sub("alt materiale i infomedia.*", "", temp)
  
  #Okay, now it would be really cool if we could remove everything that starts with "https:" and ends with "infomedia" (everything in between this
  temp = sub("https.*infomedia", "", temp)
  
  #Okay, next step - let us remove everything before "id:" ( and the thing in the space after the id)
  #Best bet is to do like this (but might create issues if we have an article that include "id: " at some point, but we just can't do anything about this at the moment - assumption that this will be right
  temp = sub(".*id: ",  "", temp)
  
    
  #Okay, so now we just need to remove everything that is not letters or numbers.
  #And unfortunately we cannot use Arnaults function and need to make our own
  #I HATE DANISH!
  #But the below works
  temp = stringr::str_replace_all(temp, "\\W", " ") #\\W means all non-word characters - thus removes everything but letters and numbers
  
  #And now we need to remove every time we have double, triple or more spaces
  #Shrink down to just one white space
  temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
  
  #okay, so now we need to remove the ID number. We now that the ID number is the first thinghy in our string. So now we split the string by space (which we needed to do at some point anyway, and then remove the first element)
  temp = strsplit(temp, " ")[[1]]
  #And now we remove the first thing in the streng
  temp = temp[-1]

  return(temp)
}
```

And now we make a function for the sentiment analysis
```{r}
#We need to set WD, for some stupid reason
setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon")
#RUN THIS LINE, hope it allows stupid danish letters

#Read in the Afinn library
afinn = read.csv("afinn.csv", header = F, encoding = "UTF-8")

afinn$V1 = as.character(afinn$V1)

#Okay, this works now, but fucks up the first word. Let us just change that quickly
afinn[1,1] = "abekat"

#And then rename the column names
colnames(afinn)[1] <- "word"
colnames(afinn)[2] <- "sentiment"


sentimentAnalysis <- function(string){
  
  #okay, we start out by making our article string into a temporary dataframe
  tempDF = as.data.frame(string)
  
  #Now we change the name of one of our columns (the column for our words in the article is right now called string - that doesn't work!)
  colnames(tempDF) <- "word"
  #We don't want the word column to be a factor. So we change it. #BE THE CHANGE YOU WANT TO SEE IN THE WORLD!
  tempDF$word = as.character(tempDF$word)
  
  
  #Okay, so now I guess we are ready to try analysing shit - And get some information from ou file name
  #First up: Newspaper
  tempDF$newspaper = substring(article, 1, 1)
  
  #Okay, now article
  tempDF$article = sub("A", "", unlist(strsplit(article, "_"))[2])
  
  #Okay, now year! YEAH!
  tempDF$year = sub(".pdf", "", sub("Y", "", unlist(strsplit(article, "_"))[4]))
  
  #And search term!
  tempDF$searchTerm = unlist(strsplit(article, "_"))[3]
  
  #And now for sentiment!
  #I guess a good way to start is by adding column names for whatever we want to get out of the analysis (and make the columns empty)
  
  
  #Okay, I guess we are writing a loop! I miss loops. Do you miss them too? <3 
  #But I guess we justed swapped long loops for longer functions..
  
  #Okay, so we have the tempDF and the afinn df and now we merge them using what is apparently a left outer join
  tempDF = dplyr::left_join(tempDF, afinn, by = "word")
  
  #Now add a column with arousal - Aka change sentiment to absolute values
  tempDF$arousal = abs(tempDF$sentiment)
  
  #Now at a row for number of words in the article
  tempDF$nWords = length(tempDF$word)
  
  #Now for number of words that actually gave os a score
  tempDF$nWordsSentiment = sum(complete.cases(tempDF$sentiment))
  
  #And let us just calculate the percentage...
  tempDF$percWordsSentiment = (sum(complete.cases(tempDF$sentiment))/length(tempDF$word))*100
  
 return(tempDF)
}


```



And now for the loop

```{r}

#Make a list of all the articles that are non-machinable (I have a folder - Because I'm cool!) (New word - yay! :D)

nmArticles = list.files(path = "C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/NonMachineRead")



#We can opeeeeeen the loooop! (Sing this in the same melody as "I can shoow you the woooorld!")

N = 1

for (article in nmArticles){
  print (article) # just to be able to follow the code, see that it is working and stuff
  print (N)
  N = N+1
  
  #Set temporary WD
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/NonMachineRead")
  
  #Okay, now we are ready to read in the article
  A <- ocr(article, engine = danish)
  
  #Okay, so our awesome function from the tesserect package helped us read the non machinable text.
  #However, we are now left with a character string. This is the same length as number of pages in the pdf - And we just want one long coherrent text
  #Is there an easier way to do this? Unlist did not work...
  AOut = NULL
  for (page in A){
    AOut = paste(AOut, page, article, sep ="")
  }
  
  #So, the loop above solved our problem - now we have the coherrent string
  #Cool. Now we want to clean the text
  cleanA = cleanText(AOut)
  
  #okay, so now we can move onto the next step... OUR SENTIMENT ANALYSIS! 
  #Let us just write a function... I need to learn to do functions instead, to avoid the insanely long loops from last semester
  
  #FUcntion is done! Good job, rainbow coloured dragon!
  dfAnalysis = sentimentAnalysis(cleanA)
  
  
  #And now we just need to write this to a csv-file!
  #EASY!
  
  #first we specify our name.
  #AKA, remove .pdf and swap it for .csv in our article name
  saveName = sub(".pdf", ".csv", article)
  
  #Set temporary WD again (but to a different place)
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/AnalysedFiles")
  write.csv(dfAnalysis, file = saveName, row.names = F)
  
}



```


##Okay, so we beat down the non machinable files.
###Now we move on to the machinable files.


First we write a new cleaning function:
```{r}

library(stringr)


cleanText <- function(string){
  
  # Make the text lowercase
  temp = tolower(string)
  
  #Now let us remove everything starting with a backslash _ Wuhuu, the code works now! :D
  temp = stringr::str_replace_all(temp, "[[:cntrl:]]", " ")
    
  #Okay, so now we just need to remove everything that is not letters or numbers.
  #And unfortunately we cannot use Arnaults function and need to make our own
  #I HATE DANISH!
  #But the below works
  temp = stringr::str_replace_all(temp, "\\W", " ") #\\W means all non-word characters - thus removes everything but letters and numbers
  
  #And now we need to remove every time we have double, triple or more spaces
  #Shrink down to just one white space
  temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
  
  #okay, so now we need to remove the article-thinghy in the end. This is the two last thinghy in our string. So now we split the string by space (which we needed to do at some point anyway, and then remove the last two elements)
  temp = strsplit(temp, " ")[[1]]
  #And now we remove the first thing in the streng
  temp = temp[-length(temp)]
  temp = temp[-length(temp)]

  return(temp)
}

```


#And now we can run the loop

```{r}
mArticles = list.files(path = "C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/MachineRead")

library(pdftools)

N = 1
for (article in mArticles){
  print (article) # just to be able to follow the code, see that it is working and stuff
  print (N)
  N = N+1
  
  #Set temporary WD
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/MachineRead")
  
  #Okay, now we are ready to read in the article
  A <- pdf_text(article)
  
  #However, we are now left with a character string. This is the same length as number of pages in the pdf - And we just want one long coherrent text
  #Is there an easier way to do this? Unlist did not work...
  AOut = NULL
  for (page in A){
    AOut = paste(AOut, page, article, sep ="")
  }
  
  #So, the loop above solved our problem - now we have the coherrent string
  #Cool. Now we want to clean the text
  cleanA = cleanText(AOut)
  
  #okay, so now we can move onto the next step... OUR SENTIMENT ANALYSIS! 
  #Let us just write a function... I need to learn to do functions instead, to avoid the insanely long loops from last semester
  
  #FUcntion is done! Good job, rainbow coloured dragon!
  dfAnalysis = sentimentAnalysis(cleanA)
  
  
  #And now we just need to write this to a csv-file!
  #EASY!
  
  #first we specify our name.
  #AKA, remove .pdf and swap it for .csv in our article name
  saveName = sub(".pdf", ".csv", article)
  
  #Set temporary WD again (but to a different place)
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/AnalysedFiles/mr")
  write.csv(dfAnalysis, file = saveName, row.names = F)
  
}



```


#Now we merge our 500 files to one file with an insane amount of rows
```{r}
N = 1

#Get a list of all the csv files
articles = list.files(path = "C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/AnalysedFiles")

for (article in articles){
  
  #set temporary wd
  setwd("C:/Users/hille/Desktop/Exam/TheTaleOfTheSilverScaledCorrelationalDragon/data/AnalysedFiles")
  
  A = read.csv(article)
  
  if (exists("sentiment") == F){
    sentiment = A
  }else {sentiment = rbind(sentiment, A)
    print(c("RAINBOW UNICORN DRAGON", N))
    N = N+1}
  }

#Now we save the big CSVfile
write.csv(sentiment, file = "bigCSVOfSentiment.csv", row.names = F)

```


